{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "905cebd4-8569-47ec-b430-3ee6d463c190",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "KA-ud0ZCYkSt"
   },
   "source": [
    "# Predicting the SOH of Batteries Using deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b170a1b8-7693-45e8-b40f-0f74f4e94716",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "jFaLFIu1BDzT"
   },
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "24ca8d9d-ca7c-4a54-9d7e-5ef6b19cbc99",
     "showTitle": false,
     "title": ""
    },
    "colab": {},
    "colab_type": "code",
    "id": "L8OwoPz1th2h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "from itertools import cycle, zip_longest\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "980787f2-7206-4a2c-ae9e-f8f53f20545e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Select the feature, loading data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the training feature in \"attribs\"\n",
    "attribs = ['cycle', 'voltage_measured', 'current_measured',  \n",
    "                \"time\"] #'temperature_measured', 'current_load', 'voltage_load',\n",
    "fn = len(attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5e25c572-baf8-4df3-86bd-f56127d9b4d3",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "colab_type": "code",
    "id": "HXC7-1FhY1_k",
    "outputId": "c3bd647e-6c5b-407c-b9e7-5cb8fc91f3fd"
   },
   "outputs": [],
   "source": [
    "# def load_data(battery, err=None):\n",
    "#     # Construct the file path based on battery and error parameters.\n",
    "#     if err is not None:\n",
    "#         base_path = f'battery_data/Err_{err}/'\n",
    "#         battery_name = f\"{battery}_LF\"\n",
    "#     else:\n",
    "#         base_path = \"battery_data/\"\n",
    "#         battery_name = battery\n",
    "\n",
    "#     # Determine the file extension (.csv or .xlsx)\n",
    "#     xlsx_path = os.path.join(base_path, f\"{battery_name}.xlsx\")\n",
    "#     csv_path = os.path.join(base_path, f\"{battery_name}.csv\")\n",
    "\n",
    "#     # If the file is .xlsx, convert it to .csv\n",
    "#     if os.path.exists(xlsx_path):\n",
    "#         df_xlsx = pd.read_excel(xlsx_path)  # Read the Excel file\n",
    "#         df_xlsx.to_csv(csv_path, index=False)  # Save as CSV\n",
    "#         print(f\"Converted {xlsx_path} to {csv_path}\")\n",
    "\n",
    "#     # Load the data from the CSV file\n",
    "#     df = pd.read_csv(csv_path)\n",
    "\n",
    "#     # Check if the expected columns exist\n",
    "#     # required_columns = {'cycle', 'type', 'ambient_temperature', 'date_time',\n",
    "#     #                     'capacity', 'voltage_measured', 'current_measured', \n",
    "#     #                     'temperature_measured', 'current_load', \n",
    "#     #                     'voltage_load', 'time'}\n",
    "#     required_columns = {'Cycle_Index', 'Start_Time', 'End_Time', 'Test_Time (s)',\n",
    "#                         'Min_Current (A)', 'Max_Current (A)', 'Min_Voltage (V)', \n",
    "#                         'Max_Voltage (V)', 'Charge_Capacity (Ah)', \n",
    "#                         'Discharge_Capacity (Ah)', 'Charge_Energy (Wh)', 'Discharge_Energy (Wh)'}\n",
    "    \n",
    "#     if not required_columns.issubset(df.columns):\n",
    "#         raise ValueError(f\"Missing required columns in {csv_path}\")\n",
    "\n",
    "#     # Convert `date_time` to a proper datetime format\n",
    "#     df['Test_Time (s)'] = pd.to_datetime(df['Test_Time (s)'])\n",
    "\n",
    "#     # Filter only discharge cycles\n",
    "#     df_discharge = df[df['Discharge_Capacity (Ah)'] > 0].copy()\n",
    "\n",
    "#     # Create dataset with time-series data\n",
    "#     dataset = df_discharge[['Cycle_Index', 'Start_Time', 'End_Time', 'Test_Time (s)',\n",
    "#                         'Min_Current (A)', 'Max_Current (A)', 'Min_Voltage (V)', \n",
    "#                         'Max_Voltage (V)', 'Charge_Capacity (Ah)', \n",
    "#                         'Discharge_Capacity (Ah)', 'Charge_Energy (Wh)', 'Discharge_Energy (Wh)']]\n",
    "\n",
    "#     # Create cycle-level summary (one row per cycle)\n",
    "#     capacity_data = df_discharge[['Cycle_Index', 'Test_Time (s)', 'Charge_Capacity (Ah)']].drop_duplicates()\n",
    "\n",
    "#     print(\"hello\")\n",
    "#     return [dataset, capacity_data]\n",
    "def load_data(battery, err=None):\n",
    "  \n",
    "    if err is not None:\n",
    "        base_path = f'battery_data/Err_{err}/'\n",
    "        battery_name = f\"{battery}_LF\"\n",
    "    else:\n",
    "        base_path = \"battery_data/\"\n",
    "        battery_name = battery\n",
    "\n",
    "    cycle_csv = os.path.join(base_path, f\"{battery_name}_cycle_data.csv\")\n",
    "    timeseries_csv = os.path.join(base_path, f\"{battery_name}_timeseries.csv\")\n",
    "\n",
    "    cycle_xlsx = os.path.join(base_path, f\"{battery_name}_cycle_data.xlsx\")\n",
    "    if os.path.exists(cycle_xlsx):\n",
    "        df_cycle_xlsx = pd.read_excel(cycle_xlsx)\n",
    "        df_cycle_xlsx.to_csv(cycle_csv, index=False)\n",
    "        print(f\"Converted {cycle_xlsx} to {cycle_csv}\")\n",
    "\n",
    "    timeseries_xlsx = os.path.join(base_path, f\"{battery_name}_timeseries.xlsx\")\n",
    "    if os.path.exists(timeseries_xlsx):\n",
    "        df_timeseries_xlsx = pd.read_excel(timeseries_xlsx)\n",
    "        df_timeseries_xlsx.to_csv(timeseries_csv, index=False)\n",
    "        print(f\"Converted {timeseries_xlsx} to {timeseries_csv}\")\n",
    "\n",
    "    df_cycle = pd.read_csv(cycle_csv)\n",
    "    required_cycle_cols = {'Cycle_Index', 'Test_Time (s)', 'Discharge_Capacity (Ah)'}\n",
    "    if not required_cycle_cols.issubset(df_cycle.columns):\n",
    "        raise ValueError(f\"Missing required columns in cycle data: {cycle_csv}\")\n",
    "\n",
    "    try:\n",
    "        df_cycle['Test_Time (s)'] = pd.to_datetime(df_cycle['Test_Time (s)'])\n",
    "    except Exception as e:\n",
    "        print(\"Cycle data 'Test_Time (s)' conversion error:\", e)\n",
    "\n",
    "    df_timeseries = pd.read_csv(timeseries_csv)\n",
    "    required_ts_cols = {'Cycle_Index', 'Test_Time (s)', 'Current (A)', 'Voltage (V)', 'Discharge_Capacity (Ah)'}\n",
    "    if not required_ts_cols.issubset(df_timeseries.columns):\n",
    "        raise ValueError(f\"Missing required columns in timeseries data: {timeseries_csv}\")\n",
    "\n",
    "    try:\n",
    "        df_timeseries['Test_Time (s)'] = pd.to_datetime(df_timeseries['Test_Time (s)'])\n",
    "    except Exception as e:\n",
    "        print(\"Timeseries data 'Test_Time (s)' conversion error:\", e)\n",
    "\n",
    "    df_timeseries['Relative_Time (s)'] = df_timeseries.groupby('Cycle_Index')['Test_Time (s)'] \\\n",
    "        .transform(lambda x: (x - x.min()).dt.total_seconds())\n",
    "\n",
    "\n",
    "    # Construct DataFrame\n",
    "    detailed_df = pd.DataFrame({\n",
    "        'cycle': df_timeseries['Cycle_Index'],\n",
    "        # 'ambient_temperature': np.nan,   \n",
    "        'date_time': df_timeseries['Test_Time (s)'],   \n",
    "        'capacity': df_timeseries['Discharge_Capacity (Ah)'],\n",
    "        'voltage_measured': df_timeseries['Voltage (V)'],\n",
    "        'current_measured': df_timeseries['Current (A)'],\n",
    "        # 'temperature_measured': np.nan,   \n",
    "        # 'current_load': np.nan,           \n",
    "        # 'voltage_load': np.nan,           \n",
    "        'time': df_timeseries['Relative_Time (s)']   \n",
    "    })\n",
    "\n",
    "    capacity_df = pd.DataFrame({\n",
    "        'cycle': df_cycle['Cycle_Index'],\n",
    "        # 'ambient_temperature': np.nan,\n",
    "        # 'date_time': df_cycle['Test_Time (s)'],\n",
    "        'capacity': df_cycle['Discharge_Capacity (Ah)']\n",
    "    })\n",
    "\n",
    "    print(\"Detailed timeseries data head:\")\n",
    "    print(detailed_df.head())\n",
    "    print(\"Detailed timeseries data shape:\", detailed_df.shape)\n",
    "    print(\"\\nCycle capacity data head:\")\n",
    "    print(capacity_df.head())\n",
    "    print(\"Cycle capacity data shape:\", capacity_df.shape)\n",
    "\n",
    "    return [\n",
    "        detailed_df,  #  ['cycle', 'ambient_temperature', 'date_time', 'capacity', 'voltage_measured',\n",
    "                      #           'current_measured', 'temperature_measured', 'current_load', 'voltage_load', 'time']\n",
    "        capacity_df   #   ['cycle', 'ambient_temperature', 'date_time', 'capacity']\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data analysis helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(log_name='log.txt'):\n",
    "    logger = logging.getLogger('mylogger')\n",
    "    logger.setLevel(level=logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - function:%(funcName)s - %(levelname)s - %(message)s',datefmt='%Y-%m-%d %H:%M')\n",
    "\n",
    "    if log_name is not None:\n",
    "        handler = logging.FileHandler(log_name)\n",
    "        handler.setLevel(logging.DEBUG)\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def eval_metrix(true_label,pred_label):\n",
    "    MAE = metrics.mean_absolute_error(true_label,pred_label)\n",
    "    MAPE = metrics.mean_absolute_percentage_error(true_label,pred_label)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(true_label,pred_label))\n",
    "    R_squared = metrics.r2_score(true_label, pred_label)   \n",
    "\n",
    "\n",
    "    return [MAE,MAPE,R_squared,RMSE]\n",
    "\n",
    "def write_to_txt(txt_name,txt):\n",
    "    with open(txt_name,'a') as f:\n",
    "        f.write(txt)\n",
    "        f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. MLP (Multi-Layer Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(nn.Module):\n",
    "    \"\"\"Sine activation function as a custom nn.Module.\"\"\"\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron with sinusoidal activation.\"\"\"\n",
    "    def __init__(self, input_dim=fn, output_dim=1, layers_num=4, hidden_dim=50, dropout=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        assert layers_num >= 2, \"layers_num must be greater than or equal to 2\"\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(layers_num):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "                layers.append(Sin())\n",
    "            elif i == layers_num - 1:\n",
    "                layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "            else:\n",
    "                layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "                layers.append(Sin())\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize weights using Xavier initialization.\"\"\"\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the MLP.\"\"\"\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN (Convolutional Neural Network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"Basic 1D CNN for regression tasks.\"\"\"\n",
    "    def __init__(self, input_dim=fn):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=24, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm1d(24),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=24, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = None  # Fully connected layer will be dynamically set\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the CNN.\"\"\"\n",
    "        N, L = x.shape[0], x.shape[1]\n",
    "        x = x.view(N, 1, L)  # Reshape for 1D convolution\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(N, -1)  # Flatten features\n",
    "        if self.fc is None or self.fc.in_features != x.shape[1]:\n",
    "            self.fc = nn.Linear(x.shape[1], 1).to(x.device)  # Dynamically set fc input size\n",
    "        out = self.fc(x)\n",
    "        return out.view(N, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=4, hidden_size=50, num_layers=2, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(50, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, L = x.shape[0], x.shape[1]\n",
    "        x = x.view(N, 1, L)\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out.view(N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. TransformerRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRegressor(nn.Module):\n",
    "    \"\"\"Transformer-based regression model.\"\"\"\n",
    "    def __init__(self, num_features=fn, d_model=64, nhead=4, num_layers=3):\n",
    "        super(TransformerRegressor, self).__init__()\n",
    "        self.input_layer = nn.Linear(num_features, d_model)\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        \n",
    "        # Initialize with learnable values instead of zeros\n",
    "        nn.init.xavier_uniform_(self.positional_encoding)\n",
    "        \n",
    "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the Transformer.\"\"\"\n",
    "        # Project to d_model dimension\n",
    "        x = self.input_layer(x)\n",
    "        \n",
    "        # Add sequence dimension\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.positional_encoding[:, :x.size(1), :]\n",
    "        \n",
    "        # Process through transformer\n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "        # Global pooling - take mean across sequence dimension\n",
    "        x = x.squeeze(1) if x.size(1) == 1 else x.mean(dim=1)\n",
    "        \n",
    "        # Project to output\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. AttentionNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionNetwork(nn.Module):\n",
    "    \"\"\"Attention-based regression model.\"\"\"\n",
    "    def __init__(self, num_features=fn, hidden_dim=64):\n",
    "        super(AttentionNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.attention_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass with attention mechanism.\"\"\"\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        attention_weights = torch.sigmoid(self.attention_layer(x))\n",
    "        x = x * attention_weights\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "The BASE class defines a baseline framework for training, validation, and testing a model with functionality for monitoring metrics and implementing early stopping. Below is the code with key sections explained in brief comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BASE():\n",
    "    def __init__(self, model, train_loader, valid_loader, test_loader, args):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model = model.to(self.device)\n",
    "        self.args = args\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.test_loader = test_loader\n",
    "\n",
    "        self.save_dir = args.save_folder\n",
    "        if not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "        self.epochs = args.epochs\n",
    "        self.logger = get_logger(os.path.join(args.save_folder, args.log_dir))\n",
    "\n",
    "        self.loss_meter = AverageMeter()\n",
    "        self.loss_func = nn.HuberLoss(delta=1.0)  # instead of nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=args.warmup_lr)\n",
    "        self.scheduler = torch.optim.Adam(self.model.parameters(), lr=args.lr)\n",
    "        self.Bestmodel_R_squared = []\n",
    "        self.Bestmodel_MAE = []\n",
    "        self.Bestmodel_MAPE = []\n",
    "        self.Bestmodel_RMSE = []\n",
    "        \n",
    "        # Updated paths\n",
    "        self.train_path = os.path.join(self.save_dir, \"true_label.npy\")\n",
    "        self.pred_path = os.path.join(self.save_dir, \"pred_label.npy\")\n",
    "\n",
    "    def clear_logger(self):\n",
    "        self.logger.removeHandler(self.logger.handlers[0])\n",
    "        self.logger.handlers.clear()\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        self.loss_meter.reset()\n",
    "        for (x1, y1) in self.train_loader:\n",
    "            x1 = x1.to(self.device)\n",
    "            y1 = y1.to(self.device)\n",
    "\n",
    "            y_pred = self.model(x1)\n",
    "            loss = self.loss_func(y_pred, y1)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            self.loss_meter.update(loss.item())\n",
    "        return self.loss_meter.avg\n",
    "\n",
    "    def valid(self, epoch):\n",
    "        self.model.eval()\n",
    "        self.loss_meter.reset()\n",
    "        with torch.no_grad():\n",
    "            for (x1, y1) in self.valid_loader:\n",
    "                x1 = x1.to(self.device)\n",
    "                y1 = y1.to(self.device)\n",
    "\n",
    "                y_pred = self.model(x1)\n",
    "                loss = self.loss_func(y_pred, y1)\n",
    "                self.loss_meter.update(loss.item())\n",
    "        return self.loss_meter.avg\n",
    "\n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        self.loss_meter.reset()\n",
    "        true_label = []\n",
    "        pred_label = []\n",
    "        with torch.no_grad():\n",
    "            for (x1, y1) in self.test_loader:\n",
    "                x1 = x1.to(self.device)\n",
    "                y_pred = self.model(x1)\n",
    "\n",
    "                true_label.append(y1.cpu().detach().numpy())\n",
    "                pred_label.append(y_pred.cpu().detach().numpy())\n",
    "\n",
    "        # Concatenate and save labels\n",
    "        true_label = np.concatenate(true_label, axis=0)\n",
    "        pred_label = np.concatenate(pred_label, axis=0)\n",
    "        \n",
    "        # Save to defined paths\n",
    "        np.save(self.train_path, true_label)\n",
    "        np.save(self.pred_path, pred_label)\n",
    "\n",
    "        return true_label, pred_label, self.train_path, self.pred_path\n",
    "\n",
    "    def train(self):\n",
    "        self.Bestmodel_R_squared.clear()\n",
    "        self.Bestmodel_MAE.clear()\n",
    "        self.Bestmodel_MAPE.clear()\n",
    "        self.Bestmodel_RMSE.clear()\n",
    "        min_loss = 10\n",
    "        early_stop = 0\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            early_stop += 1\n",
    "            train_loss = self.train_one_epoch(epoch)\n",
    "            current_lr = self.scheduler.step()\n",
    "            valid_loss = self.valid(epoch)\n",
    "\n",
    "            if valid_loss < min_loss and self.test_loader is not None:\n",
    "                min_loss = valid_loss\n",
    "                true_label, pred_label, self.train_path, self.pred_path = self.test()\n",
    "                [MAE, MAPE, MSE, RMSE] = eval_metrix(pred_label, true_label)\n",
    "                self.Bestmodel_R_squared.append(MSE)\n",
    "                self.Bestmodel_MAE.append(MAE)\n",
    "                self.Bestmodel_MAPE.append(MAPE)\n",
    "                self.Bestmodel_RMSE.append(RMSE)\n",
    "                early_stop = 0\n",
    "            if early_stop > self.args.early_stop:\n",
    "                break\n",
    "        self.clear_logger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-processing\n",
    "1. Randomly select the test data (several per each cycle)\n",
    "2. Random select and Split the rest of the HF dataset and LF dataset according to the requirements\n",
    "3. Match the dataset with labels\n",
    "4. Transfer the dataset and label to Dataloader to be trined on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assistant function for data matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(dataset, capacity):\n",
    "    # Define columns to match on: 'cycle' and 'capacity'.\n",
    "    attrib = ['cycle', 'capacity']\n",
    "    dis_ele = capacity[attrib].copy()\n",
    "\n",
    "    # Calculate SOH (State of Health) as a percentage of initial capacity.\n",
    "    initial_capacity = dis_ele['capacity'].iloc[0]\n",
    "    dis_ele['SOH'] = dis_ele['capacity'] / initial_capacity\n",
    "    capacity['SOH'] = dis_ele['SOH']\n",
    "\n",
    "    # Initialize lists for Label and Cycle.\n",
    "    Label = []\n",
    "    Cycle = []\n",
    "    \n",
    "    # Iterate over each row in dataset and match cycles with capacity data.\n",
    "    for idx, row in dataset.iterrows():\n",
    "        matched_row = capacity[capacity['cycle'] == row['cycle']]\n",
    "        \n",
    "        # If a match is found, append the corresponding SOH to Label.\n",
    "        if not matched_row.empty:\n",
    "            Label.append(matched_row['SOH'].values[0])\n",
    "            Cycle.append(row['cycle'])\n",
    "        else:\n",
    "            # If no match, append None to indicate missing data.\n",
    "            Label.append(None)\n",
    "            Cycle.append(None)\n",
    "    \n",
    "    # Convert matched data to DataFrame for easy access.\n",
    "    Label_df = pd.DataFrame({'cycle': Cycle, 'SOH': Label})\n",
    "\n",
    "    return Label_df\n",
    "\n",
    "#Normalize features exclude others \n",
    "def normalize(data, exclude_columns): \n",
    "    excluded_data = data[[exclude_columns]]   \n",
    "    features_data = data.drop(columns=[exclude_columns])   \n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    normalized_features = scaler.fit_transform(features_data)  \n",
    "    \n",
    "    normalized_dataset = pd.DataFrame(normalized_features, columns=features_data.columns)\n",
    "    normalized_dataset[exclude_columns] = excluded_data.values  \n",
    "    return normalized_dataset\n",
    "def Pre_diff(x, y):\n",
    "    x = x.values if isinstance(x, pd.DataFrame) else x\n",
    "    y = y.values if isinstance(y, pd.DataFrame) else y\n",
    "    tensor_X = torch.from_numpy(x).float()\n",
    "    tensor_Y = torch.from_numpy(y).float().view(-1, 1)\n",
    "    dataset = TensorDataset(tensor_X, tensor_Y)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaderB(dataset, split_ratios=(0.9, 0.1), batch_size=64, type='regression'):\n",
    "    \"\"\"\n",
    "    Create train and validation data loaders from the given dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: The input dataset for training and validation.\n",
    "        split_ratios (tuple): Ratios to split the dataset (train_ratio, valid_ratio).\n",
    "        batch_size (int): Batch size for data loaders.\n",
    "        type (str): Task type, typically \"regression\".\n",
    "\n",
    "    Returns:\n",
    "        train_loader: DataLoader for training data.\n",
    "        valid_loader: DataLoader for validation data.\n",
    "    \"\"\"\n",
    "    assert sum(split_ratios) == 1\n",
    "\n",
    "    train_ratio, valid_ratio = split_ratios    \n",
    "    # Split the dataset into train and validation sets\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    valid_size = int(valid_ratio * len(dataset))\n",
    " \n",
    "    if type == 'regression':\n",
    "        train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Data_processing(battery_code, err=0.02, total_data=1000, test_size=2, train_ratio=0.8, valid_ratio=0.2, type=\"regression\"):\n",
    "    \"\"\"\n",
    "    Load and preprocess battery data for training, validation, and testing.\n",
    "    \"\"\"\n",
    "    def clean_battery_data(dataset, capacity):\n",
    "        \"\"\"Remove outliers and noise from battery data\"\"\"\n",
    "        cleaned_dataset = pd.DataFrame(columns=dataset.columns)\n",
    "        cleaned_capacity = pd.DataFrame(columns=capacity.columns)\n",
    "        window_size = 5  # For moving average\n",
    "        threshold = 2.0  # Standard deviations for outlier detection\n",
    "        \n",
    "        # Calculate moving average of capacity\n",
    "        capacity['moving_avg'] = capacity['capacity'].rolling(window=window_size, center=True).mean()\n",
    "        \n",
    "        # Calculate standard deviation\n",
    "        std_dev = capacity['capacity'].std()\n",
    "        mean_capacity = capacity['capacity'].mean()\n",
    "        \n",
    "        # Create mask for valid data points\n",
    "        valid_mask = (\n",
    "            (capacity['capacity'] > 0.1) &  # Remove near-zero capacity\n",
    "            (capacity['capacity'] < 1.5) &  # Remove unreasonably high capacity\n",
    "            (abs(capacity['capacity'] - mean_capacity) <= threshold * std_dev)  # Remove statistical outliers\n",
    "        )\n",
    "        \n",
    "        # Apply mask to get cleaned data\n",
    "        cleaned_capacity = capacity[valid_mask].copy()\n",
    "        \n",
    "        # Only keep dataset rows that correspond to valid capacity measurements\n",
    "        cleaned_dataset = dataset[dataset['cycle'].isin(cleaned_capacity['cycle'])].copy()\n",
    "        \n",
    "        # Remove the moving average column as it's no longer needed\n",
    "        if 'moving_avg' in cleaned_capacity.columns:\n",
    "            cleaned_capacity = cleaned_capacity.drop('moving_avg', axis=1)\n",
    "            \n",
    "        return cleaned_dataset, cleaned_capacity\n",
    "\n",
    "    # Load the entire dataset and capacity information\n",
    "    BS_dataset, BS_capacity = load_data(battery_code) \n",
    "\n",
    "    # Clean the data before processing\n",
    "    BS_dataset, BS_capacity = clean_battery_data(BS_dataset, BS_capacity)\n",
    "\n",
    "    # Extract test dataset by selecting test_size points per cycle\n",
    "    Test_dataset = pd.DataFrame(columns=BS_dataset.columns)\n",
    "    for cycle_index, group in BS_dataset.groupby('cycle'):\n",
    "        test_points = group.sample(n=test_size, random_state=42)\n",
    "        Test_dataset = pd.concat([Test_dataset, test_points])\n",
    "        \n",
    "    # Ensure data types match and sort the test dataset\n",
    "    for col in Test_dataset.columns:\n",
    "        Test_dataset[col] = Test_dataset[col].astype(BS_dataset[col].dtype)\n",
    "\n",
    "    Test_dataset = Test_dataset.sort_values(by=['cycle', 'time']).reset_index(drop=True)\n",
    "    Test_label = match(Test_dataset, BS_capacity)\n",
    "    Test_train = normalize(Test_dataset[attribs], 'cycle')\n",
    "    print(f\"Test set size: {len(Test_train)}\")\n",
    "\n",
    "    # Create DataLoader for test data\n",
    "    test_loader = DataLoader(\n",
    "        Pre_diff(Test_train, Test_label[\"SOH\"].to_numpy()), \n",
    "        batch_size=64, \n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Remove test samples from the original dataset and sort it\n",
    "    BS_dataset = BS_dataset.drop(Test_dataset.index)\n",
    "    BS_dataset = BS_dataset.sort_values(by=['cycle', 'time']).reset_index(drop=True)\n",
    "\n",
    "    # Sample the required number of data points for training\n",
    "    if type == \"regression\":\n",
    "        BS_dataset = BS_dataset.sample(n=total_data)\n",
    "        BS_dataset = BS_dataset.sort_values(by=['cycle', 'time']).reset_index(drop=True)\n",
    "        BS_capacity = BS_capacity.merge(BS_dataset[['cycle']], on='cycle', how='inner')\n",
    "\n",
    "    # Compute labels and normalize training dataset\n",
    "    BS_label = match(BS_dataset, BS_capacity)\n",
    "    BS_train = normalize(BS_dataset[attribs], 'cycle')\n",
    "    print(f\"The total size of the dataset for the baseline task is: {len(BS_train)}\")\n",
    "\n",
    "    # Create DataLoaders for training and validation sets\n",
    "    train_loader, valid_loader = create_dataloaderB(\n",
    "        Pre_diff(BS_train, BS_label[\"SOH\"].to_numpy()),\n",
    "        split_ratios=(train_ratio, valid_ratio),\n",
    "        batch_size=64,\n",
    "        type=type\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, test_loader, BS_capacity, BS_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation, plot and save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the evaluation matrics and save to xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_soh_comparison(true_label_path, pred_label_path, hf_capacity, figsize=(12, 8), dpi=600):\n",
    "    \"\"\"\n",
    "    Plot comparison between true and predicted SOH values over cycles.\n",
    "\n",
    "    Args:\n",
    "        true_label_path (str): Path to the true SOH label data (numpy file).\n",
    "        pred_label_path (str): Path to the predicted SOH label data (numpy file).\n",
    "        hf_capacity (pd.DataFrame): DataFrame containing cycle and SOH information.\n",
    "        figsize (tuple): Figure size for plotting.\n",
    "        dpi (int): Dots per inch for figure resolution.\n",
    "    \"\"\"\n",
    "    # Load true and predicted labels\n",
    "    true_label = np.load(true_label_path)\n",
    "    pred_label = np.load(pred_label_path)\n",
    "    \n",
    "    # Flatten arrays for plotting\n",
    "    tl = true_label.flatten()\n",
    "    pl = pred_label.flatten()\n",
    "\n",
    "    tl_avg = [(tl[i] + tl[i+1]) / 2 for i in range(0, len(tl), 2)]\n",
    "    pl_avg = [(pl[i] + pl[i+1]) / 2 for i in range(0, len(pl), 2)]\n",
    "\n",
    "    cycles = np.arange(1, len(tl_avg) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(cycles, tl_avg, marker='o', linestyle='--', color='blue', label='True SOH (tl)')\n",
    "    plt.plot(cycles, pl_avg, marker='x', linestyle='-', color='red', label='Predicted SOH (pl)')\n",
    "    plt.xlabel('Cycle Index')\n",
    "    plt.ylabel('SOH')\n",
    "    plt.title('Comparison of True and Predicted SOH')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0, 1.5)  # 设置y轴范围为0到1.5\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_excel(me_matrix, n, m, Way, data_name, err, data_count, test_size):\n",
    "    \"\"\"\n",
    "    Save performance metrics to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        me_matrix (list): Matrix containing performance metrics for different runs.\n",
    "        n (int): Number of initializations.\n",
    "        m (int): Number of repetitions per initialization.\n",
    "        Way (str): Model architecture used.\n",
    "        data_name (str): Dataset name.\n",
    "        err (float): Noise level applied during preprocessing.\n",
    "        data_count (int): Total number of training data points.\n",
    "        test_size (int): Number of test points per cycle.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'n': [],\n",
    "        'm': [],\n",
    "        'R Squared': [],\n",
    "        'MAE': [],\n",
    "        'MAPE': [],\n",
    "        'RMSE': []\n",
    "    }\n",
    "\n",
    "    # Collect metrics for each repetition\n",
    "    for init_index, init_me_list in enumerate(me_matrix):\n",
    "        for repeat_index in range(m):\n",
    "            data['n'].append(init_index + 1)\n",
    "            data['m'].append(repeat_index + 1)\n",
    "            me = init_me_list[repeat_index]\n",
    "            data['R Squared'].append(me['R Squared'])\n",
    "            data['MAE'].append(me['MAE'])\n",
    "            data['MAPE'].append(me['MAPE'])\n",
    "            data['RMSE'].append(me['RMSE'])\n",
    "\n",
    "    # Compute and save average metrics for each initialization\n",
    "    for init_index, init_me_list in enumerate(me_matrix):\n",
    "        avg_me = [sum(item[key] for item in init_me_list) / len(init_me_list) for key in init_me_list[0].keys()]\n",
    "        data['n'].append(init_index + 1)\n",
    "        data['m'].append('Ave')\n",
    "        data['R Squared'].append(avg_me[0])\n",
    "        data['MAE'].append(avg_me[1])\n",
    "        data['MAPE'].append(avg_me[2])\n",
    "        data['RMSE'].append(avg_me[3])\n",
    "\n",
    "    # Compute overall average metrics\n",
    "    all_rsquared = [me['R Squared'] for init_me_list in me_matrix for me in init_me_list]\n",
    "    all_mae = [me['MAE'] for init_me_list in me_matrix for me in init_me_list]\n",
    "    all_mape = [me['MAPE'] for init_me_list in me_matrix for me in init_me_list]\n",
    "    all_rmse = [me['RMSE'] for init_me_list in me_matrix for me in init_me_list]\n",
    "\n",
    "    overall_average_me = {\n",
    "        'R Squared': sum(all_rsquared) / len(all_rsquared),\n",
    "        'MAE': sum(all_mae) / len(all_mae),\n",
    "        'MAPE': sum(all_mape) / len(all_mape),\n",
    "        'RMSE': sum(all_rmse) / len(all_rmse)\n",
    "    }\n",
    "\n",
    "    data['n'].append('Ave')\n",
    "    data['m'].append('Ave')\n",
    "    data['R Squared'].append(overall_average_me['R Squared'])\n",
    "    data['MAE'].append(overall_average_me['MAE'])\n",
    "    data['MAPE'].append(overall_average_me['MAPE'])\n",
    "    data['RMSE'].append(overall_average_me['RMSE'])\n",
    "\n",
    "    # Save data to Excel\n",
    "    df = pd.DataFrame(data)\n",
    "    save_path = f\"Final_result/Benchmark/{Way}/\"\n",
    "    file_name = f\"{data_name}_{err}_{data_count}_{test_size}.xlsx\"\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    df.to_excel(os.path.join(save_path, file_name), index=False)\n",
    "\n",
    "\n",
    "def print_evaluation_matrix(me_matrix, n, m, Way, data_name, err, data_count, test_size, plot_switch, \n",
    "                            true_label_path=None, pred_label_path=None, hf_capacity=None):\n",
    "    \"\"\"\n",
    "    Print and visualize the evaluation matrix for training results.\n",
    "\n",
    "    Args:\n",
    "        me_matrix (list): Performance metrics matrix for all repetitions.\n",
    "        n (int): Number of data initializations.\n",
    "        m (int): Number of repetitions per initialization.\n",
    "        Way (str): Model architecture used.\n",
    "        data_name (str): Dataset name.\n",
    "        err (float): Noise level applied.\n",
    "        data_count (int): Total training data points used.\n",
    "        test_size (int): Number of test points per cycle.\n",
    "        plot_switch (str): Set to 'ON' to enable result plotting.\n",
    "        true_label_path (str): Path to the true label for plotting.\n",
    "        pred_label_path (str): Path to the predicted label for plotting.\n",
    "        hf_capacity (pd.DataFrame): Cycle and true SOH data.\n",
    "    \"\"\"\n",
    "    for init_index, init_me_list in enumerate(me_matrix):\n",
    "        if plot_switch == \"ON\":\n",
    "            print(f\"Data Initialization {init_index+1} Results:\")\n",
    "            for repeat_index, me in enumerate(init_me_list):\n",
    "                print(f\"Repeat {repeat_index+1}: R Squared: {me['R Squared']:.8f}, \"\n",
    "                      f\"MAE: {me['MAE']:.6f}, \"\n",
    "                      f\"MAPE: {me['MAPE']:.6f}, \"\n",
    "                      f\"RMSE: {me['RMSE']:.6f}\")\n",
    "\n",
    "    # Compute and print average performance for each initialization\n",
    "    average_me_matrix = [[sum(item[key] for item in init_me_list) / len(init_me_list) for key in init_me_list[0].keys()] for init_me_list in me_matrix]\n",
    "    for init_index, avg_me in enumerate(average_me_matrix):\n",
    "        if plot_switch == \"ON\":\n",
    "            print(f\"Average Performance for Data Initialization {init_index+1}:\")\n",
    "            print(f\"R Squared: {avg_me[0]:.8f}, MAE: {avg_me[1]:.6f}, MAPE: {avg_me[2]:.6f}, RMSE: {avg_me[3]:.6f}\")\n",
    "\n",
    "    # Compute and print overall average performance\n",
    "    all_rsquared = [me['R Squared'] for init_me_list in me_matrix for me in init_me_list]\n",
    "    all_mae = [me['MAE'] for init_me_list in me_matrix for me in init_me_list]\n",
    "    all_mape = [me['MAPE'] for init_me_list in me_matrix for me in init_me_list]\n",
    "    all_rmse = [me['RMSE'] for init_me_list in me_matrix for me in init_me_list]\n",
    "\n",
    "    overall_average_me = {\n",
    "        'R Squared': sum(all_rsquared) / len(all_rsquared),\n",
    "        'MAE': sum(all_mae) / len(all_mae),\n",
    "        'MAPE': sum(all_mape) / len(all_mape),\n",
    "        'RMSE': sum(all_rmse) / len(all_rmse)\n",
    "    }\n",
    "\n",
    "    print(\"Overall Average Model Performance:\")\n",
    "    print(f\"R Squared: {overall_average_me['R Squared']:.8f}, \"\n",
    "          f\"MAE: {overall_average_me['MAE']:.6f}, \"\n",
    "          f\"MAPE: {overall_average_me['MAPE']:.6f}, \"\n",
    "          f\"RMSE: {overall_average_me['RMSE']:.6f}\")\n",
    "\n",
    "    # Plot the SOH comparison if plot switch is enabled\n",
    "    if plot_switch == \"ON\" and true_label_path and pred_label_path and hf_capacity is not None:\n",
    "        plot_soh_comparison(true_label_path, pred_label_path, hf_capacity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot function, using when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "997dcc39-4c0f-463b-9808-4c0092b4c8eb",
     "showTitle": false,
     "title": ""
    },
    "colab_type": "text",
    "id": "BbmGgJJr0X4q"
   },
   "source": [
    "## Main\n",
    "\n",
    "Train ()\n",
    "getargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "86dbc224-05c5-4794-b747-5f6b8fe7a66e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ADzFmLmhHGrh",
    "outputId": "5cc30f4c-0efa-48bc-a1f3-1ffb5220f66e"
   },
   "outputs": [],
   "source": [
    "class ArgsNamespace:\n",
    "    \"\"\"Class to create an object for managing hyperparameters.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "\n",
    "def load_model(args):\n",
    "    \"\"\"\n",
    "    Load the specified model based on user input.\n",
    "\n",
    "    Args:\n",
    "        args: Hyperparameters and model configurations.\n",
    "\n",
    "    Returns:\n",
    "        model: Initialized model instance.\n",
    "    \"\"\"\n",
    "    if args.model == 'MLP':\n",
    "        model = MLP()\n",
    "    elif args.model == 'CNN':\n",
    "        model = CNN()\n",
    "    elif args.model == 'LSTM':\n",
    "        model = LSTM()\n",
    "    elif args.model == 'Trans':\n",
    "        model = TransformerRegressor()\n",
    "    elif args.model == 'Atten':\n",
    "        model = AttentionNetwork()\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type specified.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_hyperparams():\n",
    "    \"\"\"\n",
    "    Define hyperparameters for the training process.\n",
    "\n",
    "    Returns:\n",
    "        dict: Hyperparameter configuration.\n",
    "    \"\"\"\n",
    "    hyperparams = {\n",
    "        'epochs': 200,  # Maximum number of training epochs\n",
    "        'early_stop': 20,  # Early stopping threshold\n",
    "        'warmup_epochs': 30,  # Number of warmup epochs\n",
    "        'warmup_lr': 0.005,  # Learning rate during warmup\n",
    "        'lr': 0.01,  # Learning rate for training\n",
    "\n",
    "        # Model structure parameters\n",
    "        'F_layers_num': 3,\n",
    "        'F_hidden_dim': 25,\n",
    "\n",
    "        # Directories\n",
    "        'log_dir': 'text testinglog.txt',\n",
    "        'save_folder': 'results_base'\n",
    "    }\n",
    "    return hyperparams\n",
    "\n",
    "\n",
    "def Run_task(init_index, m, train_loader, valid_loader, test_loader, me_list, Way):\n",
    "    \"\"\"\n",
    "    Execute the training process with repeated experiments.\n",
    "\n",
    "    Args:\n",
    "        init_index (int): Index of the current initialization.\n",
    "        m (int): Number of experiment repetitions for the current initialization.\n",
    "        train_loader: Training data loader.\n",
    "        valid_loader: Validation data loader.\n",
    "        test_loader: Test data loader.\n",
    "        me_list (list): List to store performance metrics.\n",
    "        Way (str): Model architecture (\"MLP\", \"CNN\", \"LSTM\", etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    # Load hyperparameters and initialize arguments\n",
    "    hyperparams = get_hyperparams()\n",
    "    args = ArgsNamespace(**hyperparams)\n",
    "    setattr(args, 'model', Way)  # Set the model type\n",
    "    \n",
    "    for repeat_index in range(m):\n",
    "        # Load and train the model\n",
    "        model = load_model(args)\n",
    "        trainer = BASE(model, train_loader, valid_loader, test_loader, args)\n",
    "        trainer.train()  # Execute training process\n",
    "        true_label_path = trainer.train_path\n",
    "        pred_label_path = trainer.pred_path\n",
    "        # Collect evaluation metrics\n",
    "        metrics = {\n",
    "            'R Squared': trainer.Bestmodel_R_squared[-1],\n",
    "            'MAE': trainer.Bestmodel_MAE[-1],\n",
    "            'MAPE': trainer.Bestmodel_MAPE[-1],\n",
    "            'RMSE': trainer.Bestmodel_RMSE[-1]\n",
    "        }\n",
    "        me_list.append(metrics)\n",
    "        print(f\"Repetition {init_index+1}, {repeat_index+1} results: R^2={metrics['R Squared']:.4f}, \"\n",
    "              f\"MAE={metrics['MAE']:.4f}, MAPE={metrics['MAPE']:.4f}, RMSE={metrics['RMSE']:.4f}\")\n",
    "\n",
    "    return args, true_label_path, pred_label_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Benchmark Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n",
      "CALCE_CX2-16_prism_LCO_25C_0-100_0.5-0.5C_a\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load and preprocess data\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train_loader, valid_loader, test_loader, data_capacity, data_label \u001b[38;5;241m=\u001b[39m \u001b[43mData_processing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m me_list \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Initialize list for metrics of the current initialization\u001b[39;00m\n\u001b[1;32m     25\u001b[0m args, true_label_path, pred_label_path \u001b[38;5;241m=\u001b[39m Run_task(init_index, m, train_loader, valid_loader, test_loader, me_list, Way\u001b[38;5;241m=\u001b[39mWay)\n",
      "Cell \u001b[0;32mIn[44], line 71\u001b[0m, in \u001b[0;36mData_processing\u001b[0;34m(battery_code, err, total_data, test_size, train_ratio, valid_ratio, type)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_dataset, cleaned_capacity\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Load the entire dataset and capacity information\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m BS_dataset, BS_capacity \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbattery_code\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Clean the data before processing\u001b[39;00m\n\u001b[1;32m     74\u001b[0m BS_dataset, BS_capacity \u001b[38;5;241m=\u001b[39m clean_battery_data(BS_dataset, BS_capacity)\n",
      "Cell \u001b[0;32mIn[35], line 87\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(battery, err)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCycle data \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Time (s)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m conversion error:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m---> 87\u001b[0m df_timeseries \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeseries_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m required_ts_cols \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCycle_Index\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest_Time (s)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent (A)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVoltage (V)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDischarge_Capacity (Ah)\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m required_ts_cols\u001b[38;5;241m.\u001b[39missubset(df_timeseries\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1036\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1090\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:1165\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/test/lib/python3.8/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n = 5  # Number of initialization runs \n",
    "m = 5  # Number of repetitions for each run\n",
    "plot_switch = 'ON'  # Set to 'ON' to enable plotting\n",
    "datasets = [\"CALCE_CX2-16_prism_LCO_25C_0-100_0.5-0.5C_a\", \"CALCE_CX2-25_prism_LCO_25C_0-100_0.5-0.5C_b\", \"CALCE_CX2-33_prism_LCO_25C_0-100_0.5-0.5C_d\", \"CALCE_CX2-34_prism_LCO_25C_0-100_0.5-0.5C_e\", \"CALCE_CX2-36_prism_LCO_25C_0-100_0.5-0.5C_f\", \"CALCE_CX2-37_prism_LCO_25C_0-100_0.5-0.5C_g\", \"CALCE_CX2-38_prism_LCO_25C_0-100_0.5-0.5C_h\"]  # List of datasets, \"B0006\", \"B0007\", \"B0018\"\n",
    "noise = 0.002  # Noise level, e.g., 0.005, 0.01, 0.015, 0.02\n",
    "data_count = 4000  # Total number of data points in the training set\n",
    "test_size = 2  # Number of test points per cycle. Total test set size = cycle_number * test_size\n",
    "Ways = [\"MLP\", \"CNN\", \"LSTM\", \"Trans\", \"Atten\"]  # Model architectures to evaluate ,\"\" \"CNN\", \"LSTM\", \"Trans\"\n",
    "\n",
    "# Main training loop over datasets and model types\n",
    "for dataset in datasets:\n",
    "    for Way in Ways:\n",
    "        print(Way)\n",
    "        me_matrix = []  # Initialize evaluation matrix for each dataset\n",
    "        for init_index in range(n):  # Loop through different initial data splits\n",
    "            print(dataset)\n",
    "\n",
    "            # Load and preprocess data\n",
    "            train_loader, valid_loader, test_loader, data_capacity, data_label = Data_processing(\n",
    "                dataset, err=noise, total_data=data_count, test_size=test_size,\n",
    "                train_ratio=0.8, valid_ratio=0.2, type=\"regression\"\n",
    "            )\n",
    "\n",
    "            me_list = []  # Initialize list for metrics of the current initialization\n",
    "            args, true_label_path, pred_label_path = Run_task(init_index, m, train_loader, valid_loader, test_loader, me_list, Way=Way)\n",
    "            me_matrix.append(me_list)  # Append metrics for this run\n",
    "            hf_capacity = data_capacity\n",
    "        \n",
    "        if plot_switch == \"ON\":\n",
    "            plot_soh_comparison(true_label_path, pred_label_path, data_capacity)\n",
    "\n",
    "        # Print and save evaluation results for the current dataset\n",
    "        print_evaluation_matrix(\n",
    "            me_matrix, n, m, Way, dataset, noise, data_count, test_size, plot_switch\n",
    "        )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "#LSTM_Based_SOH_Prediction_v0.1",
   "notebookOrigID": 1493499110605499,
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Battery.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
